{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6dd6151",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shairozs\\.conda\\envs\\pytorch2\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#coding=utf8\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os, time, argparse\n",
    "\n",
    "from utils import *\n",
    "from models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b880017-d66c-4c60-97b0-11dad879cc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_path = '../data/higgs/HIGGS.csv'\n",
    "dat = pd.read_csv(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1286036-2129-4a21-b083-4f661b79fead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10999999, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84772965-244d-4e06-b2e7-763fa8c9ce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10999999, 30)\n",
      "Index(['label', 'lepton  pT', 'lepton  eta', 'lepton  phi',\n",
      "       'missing energy magnitude', 'missing energy phi', 'jet 1 pt',\n",
      "       'jet 1 eta', 'jet 1 phi', 'jet 1 b-tag', 'jet 2 pt', 'jet 2 eta',\n",
      "       'jet 2 phi', 'jet 2 b-tag', 'jet 3 pt', 'jet 3 eta', 'jet 3 phi',\n",
      "       'jet 3 b-tag', 'jet 4 pt', 'jet 4 eta', 'jet 4 phi', 'jet 4 b-tag',\n",
      "       'm_jj', 'm_jjj', 'm_lv', 'm_jlv', 'm_bb', 'm_wbb', 'm_wwbb',\n",
      "       'training'],\n",
      "      dtype='object')\n",
      "   label  lepton  pT  lepton  eta  lepton  phi  missing energy magnitude  \\\n",
      "0    1.0    0.907542     0.329147     0.359412                  1.497970   \n",
      "1    1.0    0.798835     1.470639    -1.635975                  0.453773   \n",
      "2    0.0    1.344385    -0.876626     0.935913                  1.992050   \n",
      "3    1.0    1.105009     0.321356     1.522401                  0.882808   \n",
      "4    0.0    1.595839    -0.607811     0.007075                  1.818450   \n",
      "\n",
      "   missing energy phi  jet 1 pt  jet 1 eta  jet 1 phi  jet 1 b-tag  ...  \\\n",
      "0           -0.313010  1.095531  -0.557525  -1.588230     2.173076  ...   \n",
      "1            0.425629  1.104875   1.282322   1.381664     0.000000  ...   \n",
      "2            0.882454  1.786066  -1.646778  -0.942383     0.000000  ...   \n",
      "3           -1.205349  0.681466  -1.070464  -0.921871     0.000000  ...   \n",
      "4           -0.111906  0.847550  -0.566437   1.581239     2.173076  ...   \n",
      "\n",
      "   jet 4 phi  jet 4 b-tag      m_jj     m_jjj      m_lv     m_jlv      m_bb  \\\n",
      "0  -0.000819     0.000000  0.302220  0.833048  0.985700  0.978098  0.779732   \n",
      "1   0.900461     0.000000  0.909753  1.108330  0.985692  0.951331  0.803252   \n",
      "2  -1.360356     0.000000  0.946652  1.028704  0.998656  0.728281  0.869200   \n",
      "3   0.113041     0.000000  0.755856  1.361057  0.986610  0.838085  1.133295   \n",
      "4  -1.274345     3.101961  0.823761  0.938191  0.971758  0.789176  0.430553   \n",
      "\n",
      "      m_wbb    m_wwbb  training  \n",
      "0  0.992356  0.798343         1  \n",
      "1  0.865924  0.780118         1  \n",
      "2  1.026736  0.957904         1  \n",
      "3  0.872245  0.808487         1  \n",
      "4  0.961357  0.957818         1  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "train_idx = [x for x in range(dat.shape[0])]\n",
    "train_idx = [int(x < 500000) for x in train_idx] \n",
    "cols = ['label', \n",
    "        'lepton  pT', \n",
    "        'lepton  eta', \n",
    "        'lepton  phi', \n",
    "        'missing energy magnitude', \n",
    "        'missing energy phi', \n",
    "        'jet 1 pt', \n",
    "        'jet 1 eta', \n",
    "        'jet 1 phi', \n",
    "        'jet 1 b-tag', \n",
    "        'jet 2 pt', \n",
    "        'jet 2 eta', \n",
    "        'jet 2 phi', \n",
    "        'jet 2 b-tag', \n",
    "        'jet 3 pt', \n",
    "        'jet 3 eta', \n",
    "        'jet 3 phi', \n",
    "        'jet 3 b-tag', \n",
    "        'jet 4 pt', \n",
    "        'jet 4 eta', \n",
    "        'jet 4 phi', \n",
    "        'jet 4 b-tag', \n",
    "        'm_jj',\n",
    "        'm_jjj', \n",
    "        'm_lv',\n",
    "        'm_jlv', \n",
    "        'm_bb', \n",
    "        'm_wbb', \n",
    "        'm_wwbb', 'training']\n",
    "dat.columns = cols\n",
    "#dat['training'] = train_idx\n",
    "print(dat.shape)\n",
    "print(dat.columns)\n",
    "print(dat.head())\n",
    "\n",
    "class Higgs(Dataset):\n",
    "    \n",
    "    def __init__(self, dataframe, training = True):\n",
    "        self.dataframe = dataframe\n",
    "        if training:\n",
    "            self.dataframe = self.dataframe.loc[self.dataframe.training == 1, :]\n",
    "        else:\n",
    "            self.dataframe = self.dataframe.loc[self.dataframe.training == 0, :]\n",
    "            \n",
    "    def __len__(self):\n",
    "        return(self.dataframe.shape[0])\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        row = self.dataframe.iloc[i,:]\n",
    "        inp = row[[x for x in self.dataframe.columns if x not in ['label', 'training']]]\n",
    "        out = row[['label']]\n",
    "        inp = np.array(inp).astype('float32')\n",
    "        out = np.array(out).astype('uint64')\n",
    "        return(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6776e710-9397-4063-880d-7a54c51bd208",
   "metadata": {},
   "outputs": [],
   "source": [
    "hds = Higgs(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be8eb960-9f0e-4e81-b168-b333378f3339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28,) (1,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a,b = hds.__getitem__(3)\n",
    "print(a.shape, b.shape)\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "F.one_hot(torch.Tensor(b).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b4159e5-b89f-4156-9e3a-9a6575d2ae06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "qz = nn.Linear(28, 10)\n",
    "qz(torch.Tensor(a[np.newaxis, :])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfc660bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Backprop:\n",
    "\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        if args.model == \"MLP\":\n",
    "            self.model  = MLP(args)\n",
    "        if args.model == \"signMLP\":\n",
    "            self.model  = signMLP(args)\n",
    "        if args.model == \"CNN\":\n",
    "            self.model  = CNN(args)\n",
    "        if args.model == \"VGG\":\n",
    "            self.model  = VGG(args)\n",
    "        if args.model == 'KAN':\n",
    "            self.model = MNISTChebyKAN(degree = 20)\n",
    "        \n",
    "        self.model.to(device)\n",
    "        self.batch_size = args.batchsize\n",
    "        self.lambda_0   = args.lambda_\n",
    "        self.sigma      = args.sigma_\n",
    "        self.last_linear = \"output_layer\"\n",
    "\n",
    "        \n",
    "        self.opt = optim.AdamW(self.model.parameters(), lr=0.001)\n",
    "#         self.opt = optim.SGD(self.model.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n",
    "        self.iter_loss1, self.iter_loss2, self.iter_loss3 = [], [], []\n",
    "        self.track_loss1, self.track_loss2, self.track_loss3 = [], [], []\n",
    "        \n",
    "        self.loss = args.loss\n",
    "        if self.loss == \"mse\": self.output_criterion = nn.MSELoss()#y_pred, labels_float)\n",
    "        elif self.loss == \"CE\": self.output_criterion = nn.CrossEntropyLoss()#y_pred, label)\n",
    "        \n",
    "    def step(self, input_data, labels):\n",
    "        self.opt.zero_grad()\n",
    "\n",
    "        labels_float = F.one_hot(labels, num_classes=10).float()\n",
    "        \n",
    "        y_pred, hidden_zs = self.model(input_data)\n",
    "\n",
    "        if self.loss == \"mse\": \n",
    "            l = self.output_criterion(y_pred, labels_float)\n",
    "        elif self.loss == \"CE\": \n",
    "            l = self.output_criterion(y_pred, labels)\n",
    "\n",
    "        l.backward()\n",
    "        self.opt.step()\n",
    "        return(l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a278138",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kan_results_bp_degree20.csv\n",
      "Model trainable parameters:  541056\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 0. \t Training  ACC: 0.9117. \t Testing ACC: 0.9071\n",
      "16.13\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 2. \t Training  ACC: 0.9584. \t Testing ACC: 0.9440\n",
      "17.35\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 4. \t Training  ACC: 0.9753. \t Testing ACC: 0.9534\n",
      "14.75\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 6. \t Training  ACC: 0.9749. \t Testing ACC: 0.9505\n",
      "14.68\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 8. \t Training  ACC: 0.9772. \t Testing ACC: 0.9542\n",
      "14.69\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 10. \t Training  ACC: 0.9762. \t Testing ACC: 0.9477\n",
      "14.26\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 12. \t Training  ACC: 0.9882. \t Testing ACC: 0.9566\n",
      "15.82\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 14. \t Training  ACC: 0.9817. \t Testing ACC: 0.9524\n",
      "14.99\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 16. \t Training  ACC: 0.9844. \t Testing ACC: 0.9575\n",
      "14.69\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 18. \t Training  ACC: 0.9904. \t Testing ACC: 0.9622\n",
      "14.48\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 20. \t Training  ACC: 0.9843. \t Testing ACC: 0.9531\n",
      "14.81\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 22. \t Training  ACC: 0.9917. \t Testing ACC: 0.9578\n",
      "14.84\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 24. \t Training  ACC: 0.9889. \t Testing ACC: 0.9611\n",
      "15.54\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 26. \t Training  ACC: 0.9856. \t Testing ACC: 0.9554\n",
      "14.49\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 28. \t Training  ACC: 0.9969. \t Testing ACC: 0.9651\n",
      "14.71\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 30. \t Training  ACC: 0.9883. \t Testing ACC: 0.9567\n",
      "14.80\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 32. \t Training  ACC: 0.9922. \t Testing ACC: 0.9592\n",
      "14.53\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 34. \t Training  ACC: 0.9845. \t Testing ACC: 0.9520\n",
      "14.46\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 36. \t Training  ACC: 0.9978. \t Testing ACC: 0.9699\n",
      "14.55\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 38. \t Training  ACC: 0.9910. \t Testing ACC: 0.9589\n",
      "14.54\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 40. \t Training  ACC: 0.9871. \t Testing ACC: 0.9565\n",
      "14.66\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 42. \t Training  ACC: 0.9970. \t Testing ACC: 0.9651\n",
      "14.51\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 44. \t Training  ACC: 0.9984. \t Testing ACC: 0.9688\n",
      "14.91\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 46. \t Training  ACC: 0.9968. \t Testing ACC: 0.9628\n",
      "14.51\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 48. \t Training  ACC: 1.0000. \t Testing ACC: 0.9748\n",
      "14.74\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', type=str, default=\"mnist\")\n",
    "    parser.add_argument('--model', type=str, default=\"KAN\")\n",
    "    parser.add_argument('--loss', type=str, default=\"CE\")\n",
    "    parser.add_argument('--BP', type=int, default=0)\n",
    "    parser.add_argument('--HSIC', type=str, default=\"nHSIC\")\n",
    "    parser.add_argument('--kernel_x', type=str, default=\"rbf\", choices=[\"rbf\", \"student\"])\n",
    "    parser.add_argument('--kernel_h', type=str, default=\"rbf\", choices=[\"rbf\", \"student\"])\n",
    "    parser.add_argument('--kernel_y', type=str, default=\"student\", choices=[\"rbf\", \"student\"])\n",
    "    parser.add_argument('--sigma_', type=int, default=10)\n",
    "    parser.add_argument('--lambda_', type=int, default=100)\n",
    "    parser.add_argument('--batchsize', type=int, default=128)\n",
    "    parser.add_argument('--device', type=int, default=0)\n",
    "    parser.add_argument('--bn_affine', type=int, default=1)\n",
    "    parser.add_argument('--forward', type=str, default=\"n\", choices=[\"x\", \"h\", \"n\"])\n",
    "    \n",
    "    # Testing.\n",
    "    parser.add_argument('--Latinb', type=int, default=0, choices=[0, 1])\n",
    "    parser.add_argument('--Latinb_lambda', type=float, default=1.)\n",
    "    parser.add_argument('--Latinb_type', type=str, default=\"f\", choices=[\"f\", \"n\"])\n",
    "        \n",
    "    args, _ = parser.parse_known_args()\n",
    "    filename = 'kan_results_bp_degree20.csv'#get_filename(args)\n",
    "    print(filename)\n",
    "    \n",
    "    torch.manual_seed(1)\n",
    "    device = \"cuda:{}\".format(args.device)\n",
    "    batch_size = args.batchsize\n",
    "    train_loader, test_loader = load_data(args)\n",
    "    \n",
    "    logs = list()\n",
    "    backprop = Backprop(args)\n",
    "    \n",
    "    get_loss = list()\n",
    "    print(\"Model trainable parameters: \", sum(p.numel() for p in backprop.model.parameters() if p.requires_grad))\n",
    "\n",
    "    for epoch in range(50):\n",
    "        backprop.model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.view(args.batchsize, -1)\n",
    "            start = time.time()\n",
    "            loss = backprop.step(data.view(args.batchsize, -1).to(device), target.to(device))\n",
    "        if epoch % 2 == 0:\n",
    "            print(\"Input shape: \", data.shape)\n",
    "            print(\"Target shape: \", target.shape)\n",
    "            show_result(backprop, train_loader, test_loader, epoch, logs, device)\n",
    "            logs[epoch//2].append(time.time()-start)\n",
    "            print(\"{:.2f}\".format(time.time()-start))\n",
    "            start = time.time()\n",
    "\n",
    "    txt_path = os.path.join(\".\\\\\", filename+\".csv\")\n",
    "    df = pd.DataFrame(logs)\n",
    "    df.to_csv(txt_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53d7d02f-b45b-45f6-b630-ca1d7e44e743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mlp_results_bp.csv\n",
      "Model trainable parameters:  252682\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 0. \t Training  ACC: 0.9756. \t Testing ACC: 0.9692\n",
      "14.27\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 2. \t Training  ACC: 0.9916. \t Testing ACC: 0.9796\n",
      "13.85\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 4. \t Training  ACC: 0.9939. \t Testing ACC: 0.9805\n",
      "14.16\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 6. \t Training  ACC: 0.9966. \t Testing ACC: 0.9816\n",
      "19.02\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 8. \t Training  ACC: 0.9965. \t Testing ACC: 0.9817\n",
      "14.73\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 10. \t Training  ACC: 0.9971. \t Testing ACC: 0.9827\n",
      "14.07\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 12. \t Training  ACC: 0.9971. \t Testing ACC: 0.9804\n",
      "13.81\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 14. \t Training  ACC: 0.9981. \t Testing ACC: 0.9812\n",
      "14.24\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 16. \t Training  ACC: 0.9975. \t Testing ACC: 0.9815\n",
      "14.33\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 18. \t Training  ACC: 0.9988. \t Testing ACC: 0.9837\n",
      "14.54\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 20. \t Training  ACC: 0.9982. \t Testing ACC: 0.9824\n",
      "13.96\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 22. \t Training  ACC: 0.9990. \t Testing ACC: 0.9838\n",
      "15.12\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 24. \t Training  ACC: 0.9983. \t Testing ACC: 0.9825\n",
      "13.92\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 26. \t Training  ACC: 0.9985. \t Testing ACC: 0.9834\n",
      "13.86\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 28. \t Training  ACC: 0.9993. \t Testing ACC: 0.9815\n",
      "13.99\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 30. \t Training  ACC: 0.9992. \t Testing ACC: 0.9807\n",
      "13.99\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 32. \t Training  ACC: 0.9995. \t Testing ACC: 0.9819\n",
      "13.90\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 34. \t Training  ACC: 0.9990. \t Testing ACC: 0.9829\n",
      "13.93\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 36. \t Training  ACC: 0.9994. \t Testing ACC: 0.9831\n",
      "13.86\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 38. \t Training  ACC: 0.9988. \t Testing ACC: 0.9815\n",
      "14.17\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 40. \t Training  ACC: 0.9993. \t Testing ACC: 0.9821\n",
      "14.09\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 42. \t Training  ACC: 0.9995. \t Testing ACC: 0.9831\n",
      "14.05\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 44. \t Training  ACC: 0.9997. \t Testing ACC: 0.9836\n",
      "13.79\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 46. \t Training  ACC: 0.9994. \t Testing ACC: 0.9821\n",
      "13.95\n",
      "Input shape:  torch.Size([128, 784])\n",
      "Target shape:  torch.Size([128])\n",
      "EPOCH 48. \t Training  ACC: 0.9997. \t Testing ACC: 0.9828\n",
      "14.31\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--dataset', type=str, default=\"mnist\")\n",
    "    parser.add_argument('--model', type=str, default=\"MLP\")\n",
    "    parser.add_argument('--loss', type=str, default=\"CE\")\n",
    "    parser.add_argument('--BP', type=int, default=0)\n",
    "    parser.add_argument('--HSIC', type=str, default=\"nHSIC\")\n",
    "    parser.add_argument('--kernel_x', type=str, default=\"rbf\", choices=[\"rbf\", \"student\"])\n",
    "    parser.add_argument('--kernel_h', type=str, default=\"rbf\", choices=[\"rbf\", \"student\"])\n",
    "    parser.add_argument('--kernel_y', type=str, default=\"student\", choices=[\"rbf\", \"student\"])\n",
    "    parser.add_argument('--sigma_', type=int, default=10)\n",
    "    parser.add_argument('--lambda_', type=int, default=100)\n",
    "    parser.add_argument('--batchsize', type=int, default=128)\n",
    "    parser.add_argument('--device', type=int, default=0)\n",
    "    parser.add_argument('--bn_affine', type=int, default=1)\n",
    "    parser.add_argument('--forward', type=str, default=\"n\", choices=[\"x\", \"h\", \"n\"])\n",
    "    \n",
    "    # Testing.\n",
    "    parser.add_argument('--Latinb', type=int, default=0, choices=[0, 1])\n",
    "    parser.add_argument('--Latinb_lambda', type=float, default=1.)\n",
    "    parser.add_argument('--Latinb_type', type=str, default=\"f\", choices=[\"f\", \"n\"])\n",
    "        \n",
    "    args, _ = parser.parse_known_args()\n",
    "    filename = 'mlp_results_bp.csv'#get_filename(args)\n",
    "    print(filename)\n",
    "    \n",
    "    torch.manual_seed(1)\n",
    "    device = \"cuda:{}\".format(args.device)\n",
    "    batch_size = args.batchsize\n",
    "    train_loader, test_loader = load_data(args)\n",
    "    \n",
    "    logs = list()\n",
    "    backprop = Backprop(args)\n",
    "    \n",
    "    get_loss = list()\n",
    "    print(\"Model trainable parameters: \", sum(p.numel() for p in backprop.model.parameters() if p.requires_grad))\n",
    "\n",
    "    for epoch in range(50):\n",
    "        backprop.model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data = data.view(args.batchsize, -1)\n",
    "            start = time.time()\n",
    "            loss = backprop.step(data.view(args.batchsize, -1).to(device), target.to(device))\n",
    "        if epoch % 2 == 0:\n",
    "            print(\"Input shape: \", data.shape)\n",
    "            print(\"Target shape: \", target.shape)\n",
    "            show_result(backprop, train_loader, test_loader, epoch, logs, device)\n",
    "            logs[epoch//2].append(time.time()-start)\n",
    "            print(\"{:.2f}\".format(time.time()-start))\n",
    "            start = time.time()\n",
    "\n",
    "    txt_path = os.path.join(\".\\\\\", filename+\".csv\")\n",
    "    df = pd.DataFrame(logs)\n",
    "    df.to_csv(txt_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf1b4e1-2903-449a-85a3-abf63d36e74a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252682"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in hsic.model.parameters() if p.requires_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
